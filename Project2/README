# 5700 Project 2

Eric Chin
Pranav Gandhi


High Level Approach
===================

We began by considering the data flow of a Fakebook crawler, understanding the
program to perform the following tasks:

  1. Run program
  2. Connect to server
  3. Get cookies and authenticate
  4. Get HTML page
  5. Parse HTML
     - Look for flags
     - Visit every link not yet seen
  6. Quit when fifth flag is found

By outlining this, we had more specific goals to accomplish, which we did in
sequence.


Challenges
==========

At first, we had trouble with authenticating because of malformed HTTP requests
and cookie problems, but after resolving that issue, we did not encounter any
significant challenges to the program.


Testing Code
============

To test our code, we made sure each part of the program worked on its own, 
checking to make sure our HTTP requests were properly formed, our parsing
worked as intended, and our crawler visited new pages.



Old Thoughts and Outline
========================

# Overview of Idea

1. Run ./webcrawler ...
  - socket connection to server
  - build HTTP GET to /account/login
  - respond to error codes
  - deal with two cookies we get
2. http:// fakebook 
  - HTTP POST with cookies, login
  - Receive a COOKIE
3. Attach cookie to all future communications (function for post() and get() to append cookies to our requests)
  - Request homepage
  - Get HTML page
4. Parse HTML
  - look for flags (print if flag exists)
  - crawl links
  - repeat
5. When fifth flag is found, quit


# Tasks

* Parse error codes from HTTP responses
  1. Deal with each error code differently
* Dealing with cookies
* Login requires
  1. get two cookies from initial session page
     - csrftoken, sessonid
  2. use both cookies to log in
